import jieba
import mammoth
import save
import time
import streamlit as st
import jieba.posseg as pseg
from LAC import LAC


def remove_duplicates(lst):
    return list(dict.fromkeys(lst))


def processing():
    st.sidebar.header("ä¸­æ–‡äººåè¯†åˆ«è¿›åº¦")
    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()
    for i in range(1, 101):
        status_text.text("äººåæ ‡æ³¨è¿›åº¦%i%%" % i)
        progress_bar.progress(i)
        time.sleep(0.01)
    # progress_bar.empty()


def show_detail(detail_text, list):
    # ä½¿ç”¨Markdownè¯­æ³•è®¾ç½®å­—ä½“é¢œè‰²
    for i in range(len(list)):
        colored_text = f"<span style='color:red'>{list[i]}</span>"
        detail_text = detail_text.replace(list[i], colored_text)
    st.markdown(detail_text, unsafe_allow_html=True)
    return detail_text


st.set_page_config(page_title="ä¸­æ–‡äººåè¯†åˆ«", page_icon="ğŸ“‹", layout="wide")

st.title("ä¸­æ–‡äººåè¯†åˆ«")
st.write("Tips:  ç¼–å†™ä¸€ä¸ªä¸­æ–‡äººåè¯†åˆ«è½¯ä»¶ï¼Œå°†ä¸€ç¯‡ä¸­æ–‡æ–‡æœ¬ä¸­çš„äººåè¯†åˆ«å‡ºæ¥å¹¶æ ‡çº¢")
lac = LAC(mode='seg')
lac1 = LAC(mode='lac')
lac.load_customization('./task2_data/dict.txt')
lac1.load_customization('./task2_data/dict.txt')
st.markdown("""**è¯·ä¸Šä¼ éœ€å¤„ç†çš„DOCXæˆ–è€…TXTæ–‡ä»¶ï¼š**""")
uploaded = st.file_uploader("è¯·ä¸Šä¼ éœ€å¤„ç†çš„DOCXæˆ–è€…TXTæ–‡ä»¶", type=['docx', 'txt'], label_visibility="collapsed")
if uploaded is not None:
    if uploaded.name.split('.')[-1] == 'docx':
        text = mammoth.convert_to_markdown(uploaded).value
    elif uploaded.name.split('.')[-1] == 'txt':
        text = uploaded.read().decode("utf-8")
    docx_file = uploaded.name
    st.header("åŸæ–‡ï¼š")
    st.text_area(label='åŸæ–‡', value=text, height=300, label_visibility="collapsed")
    content = jieba.lcut(text, use_paddle=True)
    seg_result = lac.run(text)
    names = []
    namess = []
    namesss = []
    ls = []
    ls1 = []

    lac_result = lac1.run(seg_result)
    for i in range(len(lac_result)):
        ls.append(lac_result[i])
        ls1.append(sum(ls[i], []))
    for i in range(len(ls1)):
        if "PER" in ls1[i]:
            names.append(ls1[i])
    words = pseg.lcut(text, HMM=True, use_paddle=True)
    column = [row[0] for row in names]
    col1, col2, col3, col4 = st.columns([1, 1.1, 1, 1.1])
    with col1:
        st.subheader("jiebaåˆ†è¯ç»“æœï¼š")
        st.write(content)
    with col2:
        st.subheader("jiebaæ ‡æ³¨è¯æ€§ç»“æœï¼š")
        st.write(words)
    with col3:
        st.subheader("LACåˆ†è¯ç»“æœï¼š")
        st.write(seg_result)
    with col4:
        st.subheader("LACæ ‡æ³¨è¯æ€§ç»“æœï¼š")
        st.write(ls1)
    unique_list = remove_duplicates(column)
    min_length = 1
    longest_string = ""
    for s in unique_list:
        if len(s) > min_length:
            longest_string = s
            namesss.append(longest_string)
    for word, flag in words:
        if flag == 'nr':  # äººå
            if len(word) > min_length:
                namess.append(word)
    unique_lists = remove_duplicates(namess)
    col4, col5 = st.columns([1, 1])
    with col4:
        st.subheader("jiebaè§„åˆ™äººåè¯†åˆ«ç»“æœï¼š")
        st.write(unique_lists)
    with col5:
        st.subheader("LACæ¨¡å‹äººåè¯†åˆ«ç»“æœï¼š")
        st.write(namesss)
    st.markdown("""**è¯·é€‰æ‹©åˆ†ç±»åˆ†è¯ç»“æœå®Œæˆä¸­æ–‡äººåæ ‡æ³¨ï¼š**""")
    choice = st.selectbox(label='è¯·é€‰æ‹©åˆ†ç±»åˆ†è¯ç»“æœå®Œæˆä¸­æ–‡äººåæ ‡æ³¨', options=('jiebaè§„åˆ™äººåè¯†åˆ«ç»“æœ', 'LACæ¨¡å‹äººåè¯†åˆ«ç»“æœ', ''),
                          index=2, format_func=str, help='å¦‚æœä¸é€‰æ‹©é»˜è®¤ä½¿ç”¨æ•ˆæœæœ€å¥½çš„ä¸€ä¸ªè¯†åˆ«ç»“æœ', label_visibility="collapsed")
    if choice == 'jiebaè§„åˆ™äººåè¯†åˆ«ç»“æœ':
        st.divider()
        st.subheader('æ ‡æ³¨ç»“æœæ˜¾ç¤ºï¼š')
        show_detail(text, unique_lists)
        save.main(unique_lists, docx_file)
        processing()
        st.subheader('æ ‡æ³¨äººåæ–‡ä»¶---ä¿å­˜è·¯å¾„ï¼š' + save.readword())
    elif choice == 'LACæ¨¡å‹äººåè¯†åˆ«ç»“æœ':
        st.divider()
        st.subheader('æ ‡æ³¨ç»“æœæ˜¾ç¤ºï¼š')
        show_detail(text, namesss)
        save.main(namesss, docx_file)
        processing()
        st.subheader('æ ‡æ³¨äººåæ–‡ä»¶---ä¿å­˜è·¯å¾„ï¼š' + save.readword())

